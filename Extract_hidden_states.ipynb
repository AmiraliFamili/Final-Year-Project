{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts hidden states of QWEN model given different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Get_Go_Emo import get_go\n",
    "from Get_Isear import get_isr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goEmo = get_go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isear = get_isr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os  # Import os module for directory operations\n",
    "\n",
    "\n",
    "def extract_hidden_states(df, model_names, text_column='clean_text', batch_size=16, dataset_name=\"no_dataset_selected\", \n",
    "                         device='cuda' if torch.cuda.is_available() else 'cpu', start_from_batch=0, output_directory_name='hidden_states',\n",
    "                         use_external_storage=False, storage_device_name='Media', external_storage_path='/Volumes/'):\n",
    "    \"\"\"\n",
    "    Extracts hidden states for each text in the DataFrame using specified models.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing the text data.\n",
    "        model_names (list): List of model names to extract hidden states from.\n",
    "        text_column (str): Name of the column containing text data.\n",
    "        batch_size (int): Batch size for processing.\n",
    "        dataset_name (str): Name of the dataset being processed.\n",
    "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
    "        start_from_batch (int): Batch number to start processing from (0-based index).\n",
    "        use_external_storage (bool): If True, save to external_storage_path. Defaults to False.\n",
    "        external_storage_path (str): Path to external storage. Defaults to '/Volumes/Media/'.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Determine base directory based on storage choice\n",
    "    if use_external_storage:\n",
    "        base_dir = external_storage_path + storage_device_name + '/' + output_directory_name\n",
    "    else:\n",
    "        base_dir = output_directory_name\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"\\nProcessing model: {model_name}\")\n",
    "        model_start_time = time.time()\n",
    "        print_name = model_name.replace('/', '')\n",
    "        print(print_name)  # Output: 'QwenQwen2-7B'\n",
    "        # Load tokenizer and model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        \n",
    "        # Handle missing padding token\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        texts = df[text_column].tolist()\n",
    "        tokenized = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Create DataLoader\n",
    "        input_ids = tokenized['input_ids']\n",
    "        attention_mask = tokenized['attention_mask']\n",
    "        dataset = TensorDataset(input_ids, attention_mask)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        \n",
    "        total_batches = len(dataloader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(dataloader):\n",
    "                # Skip batches before the starting batch\n",
    "                if batch_idx < start_from_batch:\n",
    "                    continue\n",
    "                    \n",
    "                all_hidden_dicts = []\n",
    "                batch_start_time = time.time()\n",
    "                \n",
    "                input_ids_batch, attention_mask_batch = [t.to(device) for t in batch]\n",
    "                \n",
    "                # Get model outputs\n",
    "                outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
    "                hidden_states = outputs.hidden_states\n",
    "                \n",
    "                # Process each example in the batch\n",
    "                current_batch_size = input_ids_batch.size(0)\n",
    "                for i in range(current_batch_size):\n",
    "                    example_hidden = {}\n",
    "                    for layer_idx, layer in enumerate(hidden_states):\n",
    "                        cls_embedding = layer[i, 0, :].cpu().numpy().tolist()\n",
    "                        example_hidden[f'layer_{layer_idx}'] = cls_embedding\n",
    "                    all_hidden_dicts.append(example_hidden)\n",
    "                \n",
    "                # Calculate batch processing time\n",
    "                batch_time = time.time() - batch_start_time\n",
    "                \n",
    "                # Print progress with time information\n",
    "                print(\n",
    "                    f\"Batch {batch_idx + 1}/{total_batches} | \"\n",
    "                    f\"Time: {batch_time:.2f}s | \"\n",
    "                    f\"Avg: {(time.time() - model_start_time)/(batch_idx + 1 - start_from_batch):.2f}s/batch\", \n",
    "                    end='\\r'\n",
    "                )\n",
    "\n",
    "                # Save individual model's hidden states to JSON file in the determined directory\n",
    "                output_filename = os.path.join(base_dir, f\"{print_name}_{dataset_name}_{batch_idx}.json\")\n",
    "                with open(output_filename, 'w') as f:\n",
    "                    json.dump(all_hidden_dicts, f, indent=2)  # indent for pretty-printing\n",
    "                    \n",
    "        \n",
    "        # Print final summary\n",
    "        total_time = time.time() - model_start_time\n",
    "        processed_batches = total_batches - start_from_batch\n",
    "        print(f\"\\nCompleted {model_name} in {total_time:.2f}s ({total_time/processed_batches:.4f}s/batch)\")\n",
    "        print(f\"Saved hidden states to {output_filename}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del model, tokenizer\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nAll models processed and hidden states saved in '{base_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other Model names\n",
    "# 'Qwen/Qwen2-7B'\n",
    "# 'Qwen/Qwen-7B'\n",
    "# 'gpt2'\n",
    "# 'bert-base-uncased'\n",
    "# 'Qwen/Qwen2-0.5B'\n",
    "\n",
    "# Example usage\n",
    "model_names = ['Qwen/Qwen2-0.5B']  # Replace with your models\n",
    "\n",
    "# Process goEmo dataset\n",
    "goEmo_with_hidden = extract_hidden_states(goEmo, model_names, start_from_batch=654, dataset_name=\"goEmo\", use_external_storage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import describe_hidden_states, analyze_hidden_states, describe_all_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "analysis = analyze_hidden_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all files in the default hidden_states directory\n",
    "describe_all_hidden_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

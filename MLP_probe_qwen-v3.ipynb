{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goemo_path_train = \"Go_Emotion_Google/go_emotions_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reuse the GoEmotionDataset class\n",
    "class GoEmotionDataset:\n",
    "    \"\"\"\n",
    "    A class to load, preprocess, and analyze the GoEmotions dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    EMOTIONS = [\n",
    "        'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', \n",
    "        'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', \n",
    "        'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief',\n",
    "        'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', \n",
    "        'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "    ]\n",
    "    \n",
    "    POSITIVE_EMOTIONS = {\n",
    "        \"admiration\", \"amusement\", \"approval\", \"caring\", \"desire\", \"excitement\",\n",
    "        \"gratitude\", \"joy\", \"love\", \"optimism\", \"pride\", \"relief\"\n",
    "    }\n",
    "    \n",
    "    AMBIGUOUS_EMOTIONS = {\n",
    "        \"confusion\", \"curiosity\", \"surprise\", \"realization\", \"neutral\"\n",
    "    }\n",
    "    \n",
    "    NEGATIVE_EMOTIONS = {\n",
    "        \"anger\", \"annoyance\", \"disappointment\", \"disapproval\", \"disgust\",\n",
    "        \"embarrassment\", \"fear\", \"grief\", \"nervousness\", \"remorse\", \"sadness\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, train_path: str, test_path: str, val_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by loading and processing the data.\n",
    "        \n",
    "        Args:\n",
    "            train_path: Path to training data CSV\n",
    "            test_path: Path to test data CSV\n",
    "            val_path: Path to validation data CSV\n",
    "        \"\"\"\n",
    "        self.df = self._load_data(train_path, test_path, val_path)\n",
    "        self._preprocess_data()\n",
    "        \n",
    "    def _load_data(self, train_path: str, test_path: str, val_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Load and combine the dataset components.\"\"\"\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        val_df = pd.read_csv(val_path)\n",
    "        \n",
    "        main_df = pd.concat([train_df, test_df, val_df], axis=0)\n",
    "        main_df = main_df.reset_index(drop=True)\n",
    "        main_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        return main_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def _preprocess_text(text: str) -> str:\n",
    "        \"\"\"Clean and normalize text data.\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Preprocessing logic from the original class\n",
    "        return text.lower()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _string_to_list(label_str: str) -> List[int]:\n",
    "        \"\"\"Convert string representation of array to list of integers.\"\"\"\n",
    "        return [int(x) for x in label_str.strip('[]').replace(',', '').split()]\n",
    "    \n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"Apply all preprocessing steps to the dataset.\"\"\"\n",
    "        # Clean text\n",
    "        self.df['clean_text'] = self.df['text'].apply(self._preprocess_text)\n",
    "        \n",
    "        # Ensure labels column contains lists\n",
    "        if 'labels' in self.df.columns and isinstance(self.df['labels'].iloc[0], str):\n",
    "            self.df['labels'] = self.df['labels'].apply(self._string_to_list)\n",
    "        \n",
    "        # Create one-hot encodings for emotions\n",
    "        for i, emotion in enumerate(self.EMOTIONS):\n",
    "            self.df[emotion] = self.df['labels'].apply(lambda x: 1 if i in x else 0)\n",
    "        \n",
    "        # Get the dominant emotion for each text\n",
    "        self.df['dominant_emotion'] = self.df.apply(\n",
    "            lambda row: self.EMOTIONS[np.argmax([row[emotion] for emotion in self.EMOTIONS])], \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        self.df = self.df.drop(columns=['text', 'id'] if 'id' in self.df.columns else ['text'])\n",
    "    \n",
    "    def get_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Return the processed DataFrame.\"\"\"\n",
    "        return self.df.copy()\n",
    "\n",
    "    def get_emotion_labels(self) -> List[str]:\n",
    "        \"\"\"Return the list of emotion labels.\"\"\"\n",
    "        return self.EMOTIONS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class HiddenStatesDataset(Dataset):\n",
    "    \"\"\"Dataset for hidden states and labels.\"\"\"\n",
    "    def __init__(self, hidden_states, labels):\n",
    "        self.hidden_states = hidden_states\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.hidden_states)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.hidden_states[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "class EnhancedProbe(nn.Module):\n",
    "    \"\"\"Enhanced probe with multiple hidden layers and dropout.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.3):\n",
    "        super(EnhancedProbe, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "            layers.append(nn.GELU())\n",
    "            #layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = dim\n",
    "            \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import ijson\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class HiddenStatesDataset(Dataset):\n",
    "    \"\"\"Dataset for hidden states and labels.\"\"\"\n",
    "    def __init__(self, hidden_states, labels):\n",
    "        self.hidden_states = hidden_states\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.hidden_states[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "class EnhancedProbe(nn.Module):\n",
    "    \"\"\"Enhanced probe architecture with multiple hidden layers.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = dim\n",
    "            \n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class OptimizedProbeAnalyzer:\n",
    "    \"\"\"Optimized analyzer for training and evaluating probes on hidden states.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_states_dir: str, go_dataset, max_batches: int = None, device=None, chunk_size: int = 500):\n",
    "        \"\"\"\n",
    "        Initialize the ProbeAnalyzer with optimized data loading.\n",
    "        \n",
    "        Args:\n",
    "            hidden_states_dir: Directory containing hidden states JSON files\n",
    "            go_dataset: GoEmotionDataset instance\n",
    "            max_batches: Maximum number of batches to load (None for all)\n",
    "            device: Device to run computations on (defaults to CUDA if available)\n",
    "            chunk_size: Number of files to load at once\n",
    "        \"\"\"\n",
    "        self.hidden_states_dir = hidden_states_dir\n",
    "        self.go_dataset = go_dataset\n",
    "        self.max_batches = max_batches\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "        # Find all hidden states files\n",
    "        self.hidden_states_files = sorted([\n",
    "            f for f in os.listdir(hidden_states_dir) \n",
    "            if f.startswith('QwenQwen2-7B_goEmo_') and f.endswith('.json')\n",
    "        ])\n",
    "        \n",
    "        # Extract indices from filenames for ordering\n",
    "        indices = [int(re.search(r'goEmo_(\\d+)\\.json', f).group(1)) for f in self.hidden_states_files]\n",
    "        self.hidden_states_files = [f for _, f in sorted(zip(indices, self.hidden_states_files))]\n",
    "        \n",
    "        # Limit the number of batches if specified\n",
    "        if self.max_batches is not None:\n",
    "            self.hidden_states_files = self.hidden_states_files[:self.max_batches]\n",
    "            print(f\"Analysis limited to {len(self.hidden_states_files)} batches\")\n",
    "        \n",
    "        # Initialize metrics storage\n",
    "        self.metrics = {}\n",
    "        self.stats = {}\n",
    "        \n",
    "        # Identify layers and prepare dataset without loading all data\n",
    "        self._identify_layers()\n",
    "        self._prepare_dataset()\n",
    "    \n",
    "    def _identify_layers(self):\n",
    "        \"\"\"Identify available layers from first file without loading all data.\"\"\"\n",
    "        print(\"Identifying layer structure...\")\n",
    "        with open(os.path.join(self.hidden_states_dir, self.hidden_states_files[0]), 'r') as f:\n",
    "            first_batch = json.load(f)\n",
    "            first_example = first_batch[0]\n",
    "            self.layers = [key for key in first_example.keys() if key.startswith('layer_')]\n",
    "        \n",
    "        print(f\"Identified {len(self.layers)} layers\")\n",
    "        \n",
    "        # Calculate total examples by reading batch sizes\n",
    "        self.total_examples = 0\n",
    "        self.batch_sizes = []\n",
    "        \n",
    "        for file_name in tqdm(self.hidden_states_files, desc=\"Counting examples\"):\n",
    "            with open(os.path.join(self.hidden_states_dir, file_name), 'r') as f:\n",
    "                batch_data = json.load(f)\n",
    "                batch_size = len(batch_data)\n",
    "                self.total_examples += batch_size\n",
    "                self.batch_sizes.append(batch_size)\n",
    "        \n",
    "        print(f\"Total examples: {self.total_examples}\")\n",
    "    \n",
    "    def _prepare_dataset(self):\n",
    "        \"\"\"Prepare dataset metadata and train/test splits.\"\"\"\n",
    "        df = self.go_dataset.get_data()\n",
    "        \n",
    "        # Calculate which indices are valid (within dataset bounds)\n",
    "        self.valid_mask = [True] * min(self.total_examples, len(df))\n",
    "        self.valid_mask += [False] * max(0, self.total_examples - len(df))\n",
    "        \n",
    "        # Get labels only for valid indices\n",
    "        valid_indices = np.where(self.valid_mask)[0]\n",
    "        self.labels = df.iloc[valid_indices]['dominant_emotion'].values\n",
    "        self.encoded_labels = self.label_encoder.fit_transform(self.labels)\n",
    "        \n",
    "        # Split data into train and test sets (80/20) using sklearn's train_test_split\n",
    "        indices = np.arange(len(valid_indices))\n",
    "        self.train_indices, self.test_indices = train_test_split(\n",
    "            indices, test_size=0.2, random_state=42, stratify=self.encoded_labels\n",
    "        )\n",
    "        \n",
    "        print(f\"Prepared metadata for {len(valid_indices)} valid examples\")\n",
    "        print(f\"Train set: {len(self.train_indices)}, Test set: {len(self.test_indices)}\")\n",
    "\n",
    "    def _load_batch_file(self, file_path):\n",
    "        \"\"\"Optimized batch file loading using ijson\"\"\"\n",
    "        with open(file_path, 'r') as f:\n",
    "            return list(ijson.items(f, 'item'))\n",
    "    \n",
    "    def analyze_all_layers(self, layers_to_analyze, batch_size=32, epochs=50, max_workers=4):\n",
    "        \"\"\"Faster analysis with parallel file loading\"\"\"\n",
    "        print(f\"Training probes for layers: {layers_to_analyze}\")\n",
    "        layers_to_analyze = sorted(layers_to_analyze)\n",
    "        \n",
    "        # Initialize data structures\n",
    "        all_data = {\n",
    "            'train': {'hidden_states': defaultdict(list), 'labels': defaultdict(list)},\n",
    "            'test': {'hidden_states': defaultdict(list), 'labels': defaultdict(list), 'raw_labels': defaultdict(list)}\n",
    "        }\n",
    "        \n",
    "        # Process files in parallel\n",
    "        def process_file(file_name):\n",
    "            try:\n",
    "                file_path = os.path.join(self.hidden_states_dir, file_name)\n",
    "                batch_data = self._load_batch_file(file_path)\n",
    "                \n",
    "                file_results = {\n",
    "                    'train': defaultdict(list),\n",
    "                    'test': defaultdict(list)\n",
    "                }\n",
    "                \n",
    "                # Process examples\n",
    "                for example in batch_data:\n",
    "                    # [Same processing logic as before]\n",
    "                    pass\n",
    "                    \n",
    "                return file_results\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_name}: {str(e)}\")\n",
    "                return None\n",
    "        \n",
    "        print(\"Loading data with parallel processing...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = []\n",
    "            for chunk_start in range(0, len(self.hidden_states_files), self.chunk_size):\n",
    "                chunk_files = self.hidden_states_files[chunk_start:chunk_start + self.chunk_size]\n",
    "                futures.extend(executor.submit(process_file, fname) for fname in chunk_files)\n",
    "            \n",
    "            for future in tqdm(futures, desc=\"Processing files\"):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    # Aggregate results\n",
    "                    pass\n",
    "        \n",
    "        print(f\"Data loaded in {time.time()-start_time:.2f} seconds\")\n",
    "\n",
    "    def _train_probe_for_layer(self, layer_key, train_hidden_states, train_labels, \n",
    "                             test_hidden_states, test_labels, test_raw_labels, \n",
    "                             batch_size, epochs):\n",
    "        \"\"\"Train probe and return metrics for both train and test sets\"\"\"\n",
    "        # [Existing training code, but modified to return both train and test metrics]\n",
    "        \n",
    "        # Calculate train metrics\n",
    "        train_preds = self._get_predictions(model, train_hidden_states, batch_size)\n",
    "        train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "        \n",
    "        return {\n",
    "            'train': {\n",
    "                'accuracy': train_accuracy,\n",
    "                'confusion_matrix': confusion_matrix(train_labels, train_preds),\n",
    "                'hidden_states': train_hidden_states,\n",
    "                'labels': [self.label_encoder.inverse_transform([l])[0] for l in train_labels]\n",
    "            },\n",
    "            'test': {\n",
    "                'accuracy': test_accuracy,\n",
    "                'confusion_matrix': test_cm,\n",
    "                'hidden_states': test_hidden_states,\n",
    "                'labels': test_raw_labels,\n",
    "                'pred_labels': test_pred_emotions\n",
    "            },\n",
    "            'loss_curves': {\n",
    "                'train': train_losses,\n",
    "                'val': val_losses\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _get_predictions(self, model, hidden_states, batch_size):\n",
    "        \"\"\"Get predictions for a set of hidden states\"\"\"\n",
    "        dataset = HiddenStatesDataset(hidden_states, np.zeros(len(hidden_states)))  # Dummy labels\n",
    "        loader = DataLoader(dataset, batch_size=batch_size)\n",
    "        \n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                _, batch_preds = torch.max(outputs, 1)\n",
    "                preds.extend(batch_preds.cpu().numpy())\n",
    "        return preds\n",
    "\n",
    "    def _analyze_hidden_states(self, layer_idx, hidden_states, labels):\n",
    "        \"\"\"Analyze hidden states statistics.\"\"\"\n",
    "        hidden_states = np.array(hidden_states)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Calculate centroids\n",
    "        unique_emotions = np.unique(labels)\n",
    "        centroids = {}\n",
    "        for emotion in unique_emotions:\n",
    "            emotion_states = hidden_states[labels == emotion]\n",
    "            if len(emotion_states) > 0:\n",
    "                centroids[emotion] = emotion_states.mean(axis=0)\n",
    "        \n",
    "        # Calculate centroid similarities\n",
    "        centroid_similarities = {}\n",
    "        for i, e1 in enumerate(unique_emotions):\n",
    "            for e2 in unique_emotions[i+1:]:\n",
    "                if e1 in centroids and e2 in centroids:\n",
    "                    c1, c2 = centroids[e1], centroids[e2]\n",
    "                    similarity = np.dot(c1, c2) / (np.linalg.norm(c1) * np.linalg.norm(c2))\n",
    "                    centroid_similarities[f\"{e1}_vs_{e2}\"] = similarity\n",
    "        \n",
    "        # Silhouette score\n",
    "        try:\n",
    "            silhouette = silhouette_score(hidden_states, labels) if len(unique_emotions) > 1 else -1\n",
    "        except:\n",
    "            silhouette = -1\n",
    "        \n",
    "        return {\n",
    "            'centroids': centroids,\n",
    "            'centroid_similarities': centroid_similarities,\n",
    "            'silhouette_score': silhouette,\n",
    "            'viz_labels': labels\n",
    "        }\n",
    "\n",
    "    def save_results(self, output_path: str):\n",
    "        \"\"\"Save all results to a file.\"\"\"\n",
    "        results = {\n",
    "            'metrics': self.metrics,\n",
    "            'stats': self.stats,\n",
    "            'label_encoder': self.label_encoder,\n",
    "            'emotion_labels': self.go_dataset.get_emotion_labels(),\n",
    "            'layer_order': sorted(self.metrics.keys(), key=lambda x: int(x.split('_')[1]))\n",
    "        }\n",
    "        torch.save(results, output_path)\n",
    "\n",
    "    @classmethod\n",
    "    def load_results(cls, input_path: str):\n",
    "        \"\"\"Load saved results from file.\"\"\"\n",
    "        return torch.load(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class ProbeVisualizer:\n",
    "    \"\"\"Visualizer with separate train/test plots and larger fonts.\"\"\"\n",
    "    \n",
    "    def __init__(self, analysis_results):\n",
    "        self.results = analysis_results\n",
    "        self._setup_plot_styles()\n",
    "    \n",
    "    def _setup_plot_styles(self):\n",
    "        \"\"\"Configure consistent plotting styles\"\"\"\n",
    "        plt.rcParams.update({\n",
    "            'font.size': 14,\n",
    "            'axes.titlesize': 18,\n",
    "            'axes.labelsize': 16,\n",
    "            'xtick.labelsize': 13,\n",
    "            'ytick.labelsize': 13,\n",
    "            'legend.fontsize': 12,\n",
    "            'figure.titlesize': 20\n",
    "        })\n",
    "        sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    def visualize_all(self, output_dir='results', dpi=300):\n",
    "        \"\"\"Generate all visualizations with train/test separation\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        self.plot_performance_metrics(output_dir, dpi)  # Renamed from plot_combined_metrics\n",
    "        self.plot_accuracy_comparison(output_dir, dpi)\n",
    "        self.plot_silhouette_scores(output_dir, dpi)\n",
    "        \n",
    "        for layer in self.results['layer_order']:\n",
    "            self.plot_confusion_matrices(layer, output_dir, dpi)\n",
    "            self.plot_tsne_projections(layer, output_dir, dpi)\n",
    "            self.plot_loss_curves(layer, output_dir, dpi)\n",
    "        \n",
    "        self.save_summary_table(output_dir)\n",
    "        print(f\"All visualizations saved to {output_dir}\")\n",
    "\n",
    "    def plot_performance_metrics(self, output_dir, dpi=300):\n",
    "        \"\"\"Plot layer-wise performance metrics (originally called plot_combined_metrics)\"\"\"\n",
    "        metrics = {\n",
    "            'Accuracy': [self.results['metrics'][layer]['test']['accuracy'] for layer in self.results['layer_order']],\n",
    "            'Macro F1': [self.results['metrics'][layer]['test']['macro_f1'] for layer in self.results['layer_order']],\n",
    "            'Weighted F1': [self.results['metrics'][layer]['test']['weighted_f1'] for layer in self.results['layer_order']]\n",
    "        }\n",
    "        \n",
    "        layer_indices = [int(layer.split('_')[1]) for layer in self.results['layer_order']]\n",
    "        \n",
    "        plt.figure(figsize=(14, 8), dpi=dpi)\n",
    "        for metric_name, values in metrics.items():\n",
    "            plt.plot(layer_indices, values, marker='o', markersize=8, linewidth=2, label=metric_name)\n",
    "        \n",
    "        plt.xlabel('Layer Index', fontweight='bold')\n",
    "        plt.ylabel('Score', fontweight='bold')\n",
    "        plt.title('Layer-wise Performance Metrics (Test Set)', fontweight='bold', pad=20)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'performance_metrics.png'), bbox_inches='tight', dpi=dpi)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_accuracy_comparison(self, output_dir, dpi=300):\n",
    "        \"\"\"Plot train vs test accuracy across layers\"\"\"\n",
    "        layers = self.results['layer_order']\n",
    "        train_acc = [self.results['metrics'][l]['train']['accuracy'] for l in layers]\n",
    "        test_acc = [self.results['metrics'][l]['test']['accuracy'] for l in layers]\n",
    "        layer_nums = [int(l.split('_')[1]) for l in layers]\n",
    "        \n",
    "        plt.figure(figsize=(12, 7), dpi=dpi)\n",
    "        plt.plot(layer_nums, train_acc, 'o-', label='Train Accuracy', linewidth=2)\n",
    "        plt.plot(layer_nums, test_acc, 'o-', label='Test Accuracy', linewidth=2)\n",
    "        \n",
    "        plt.xlabel('Layer Index', fontweight='bold')\n",
    "        plt.ylabel('Accuracy', fontweight='bold')\n",
    "        plt.title('Train vs Test Accuracy by Layer', fontweight='bold', pad=20)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'accuracy_comparison.png'), bbox_inches='tight', dpi=dpi)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_silhouette_scores(self, output_dir, dpi=300):\n",
    "        \"\"\"Plot silhouette scores across layers\"\"\"\n",
    "        silhouette_scores = [self.results['stats'][layer]['test']['silhouette_score'] for layer in self.results['layer_order']]\n",
    "        layer_indices = [int(layer.split('_')[1]) for layer in self.results['layer_order']]\n",
    "        \n",
    "        plt.figure(figsize=(12, 7), dpi=dpi)\n",
    "        plt.plot(layer_indices, silhouette_scores, marker='o', markersize=8, linewidth=2, color='darkorange')\n",
    "        \n",
    "        plt.xlabel('Layer Index', fontweight='bold')\n",
    "        plt.ylabel('Silhouette Score', fontweight='bold')\n",
    "        plt.title('Layer-wise Cluster Separation (Test Set)', fontweight='bold', pad=20)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'silhouette_scores.png'), bbox_inches='tight', dpi=dpi)\n",
    "        plt.close()\n",
    "\n",
    "    def plot_confusion_matrices(self, layer, output_dir, dpi=300):\n",
    "        \"\"\"Plot both train and test confusion matrices for a specific layer\"\"\"\n",
    "        for split in ['train', 'test']:\n",
    "            cm = self.results['metrics'][layer][split]['confusion_matrix']\n",
    "            labels = self.results['metrics'][layer][split]['labels']\n",
    "            \n",
    "            # Normalize and get top emotions\n",
    "            with np.errstate(invalid='ignore'):\n",
    "                cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "                cm_percent = np.nan_to_num(cm_percent, nan=0.0)\n",
    "            \n",
    "            emotion_counts = cm.sum(axis=1)\n",
    "            top_idx = np.argsort(emotion_counts)[-10:]  # Top 10 emotions\n",
    "            top_emotions = [self.results['emotion_labels'][i] for i in top_idx]\n",
    "            cm_top = cm_percent[top_idx][:, top_idx]\n",
    "            \n",
    "            plt.figure(figsize=(14, 12), dpi=dpi)\n",
    "            sns.heatmap(\n",
    "                cm_top, \n",
    "                annot=True, \n",
    "                fmt='.1f', \n",
    "                cmap='Blues',\n",
    "                xticklabels=top_emotions,\n",
    "                yticklabels=top_emotions,\n",
    "                annot_kws={'size': 11}\n",
    "            )\n",
    "            plt.title(f'Confusion Matrix ({split.capitalize()} Set) - {layer}', fontweight='bold', pad=20)\n",
    "            plt.xlabel('Predicted Emotion', fontweight='bold')\n",
    "            plt.ylabel('True Emotion', fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                os.path.join(output_dir, f'confusion_{split}_{layer}.png'), \n",
    "                bbox_inches='tight', \n",
    "                dpi=dpi\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "    def plot_tsne_projections(self, layer, output_dir, dpi=300, perplexity=30):\n",
    "        \"\"\"Generate t-SNE plots for both train and test sets of a specific layer\"\"\"\n",
    "        for split in ['train', 'test']:\n",
    "            hidden_states = np.array(self.results['metrics'][layer][split]['hidden_states'])\n",
    "            labels = self.results['metrics'][layer][split]['labels']\n",
    "            \n",
    "            # Subsample if needed\n",
    "            if len(hidden_states) > 1000:\n",
    "                idx = np.random.choice(len(hidden_states), 1000, replace=False)\n",
    "                hidden_states = hidden_states[idx]\n",
    "                labels = [labels[i] for i in idx]\n",
    "            \n",
    "            # Compute t-SNE\n",
    "            try:\n",
    "                tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)\n",
    "                tsne_result = tsne.fit_transform(hidden_states)\n",
    "            except:\n",
    "                print(f\"Skipping t-SNE for {layer} {split} set due to error\")\n",
    "                continue\n",
    "            \n",
    "            # Plot with top emotions\n",
    "            unique_emotions, counts = np.unique(labels, return_counts=True)\n",
    "            top_emotions = unique_emotions[np.argsort(counts)[-5:]]  # Top 5 emotions\n",
    "            \n",
    "            plt.figure(figsize=(12, 10), dpi=dpi)\n",
    "            colors = plt.cm.tab10(np.linspace(0, 1, len(top_emotions)))\n",
    "            \n",
    "            for i, emotion in enumerate(top_emotions):\n",
    "                mask = np.array(labels) == emotion\n",
    "                plt.scatter(\n",
    "                    tsne_result[mask, 0], \n",
    "                    tsne_result[mask, 1], \n",
    "                    label=emotion,\n",
    "                    color=colors[i],\n",
    "                    alpha=0.7,\n",
    "                    s=50\n",
    "                )\n",
    "            plt.title(f't-SNE Projection ({split.capitalize()} Set) - {layer}', fontweight='bold', pad=20)\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                os.path.join(output_dir, f'tsne_{split}_{layer}.png'), \n",
    "                bbox_inches='tight', \n",
    "                dpi=dpi\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "    def plot_loss_curves(self, layer, output_dir, dpi=300):\n",
    "        \"\"\"Plot training/validation loss curves for a specific layer\"\"\"\n",
    "        train_losses = self.results['metrics'][layer]['loss_curves']['train']\n",
    "        val_losses = self.results['metrics'][layer]['loss_curves']['val']\n",
    "        \n",
    "        plt.figure(figsize=(12, 7), dpi=dpi)\n",
    "        plt.plot(train_losses, label='Training Loss', linewidth=2)\n",
    "        plt.plot(val_losses, label='Validation Loss', linewidth=2)\n",
    "        \n",
    "        plt.xlabel('Epoch', fontweight='bold')\n",
    "        plt.ylabel('Loss', fontweight='bold')\n",
    "        plt.title(f'Training Progress - {layer}', fontweight='bold', pad=20)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            os.path.join(output_dir, f'loss_curves_{layer}.png'), \n",
    "            bbox_inches='tight', \n",
    "            dpi=dpi\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    def save_summary_table(self, output_dir):\n",
    "        \"\"\"Save metrics summary as CSV and HTML\"\"\"\n",
    "        summary_data = []\n",
    "        for layer in self.results['layer_order']:\n",
    "            summary_data.append({\n",
    "                'Layer': int(layer.split('_')[1]),\n",
    "                'Train Accuracy': self.results['metrics'][layer]['train']['accuracy'],\n",
    "                'Test Accuracy': self.results['metrics'][layer]['test']['accuracy'],\n",
    "                'Test Macro F1': self.results['metrics'][layer]['test']['macro_f1'],\n",
    "                'Test Weighted F1': self.results['metrics'][layer]['test']['weighted_f1'],\n",
    "                'Silhouette Score': self.results['stats'][layer]['test']['silhouette_score']\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Save CSV\n",
    "        df.to_csv(os.path.join(output_dir, 'metrics_summary.csv'), index=False)\n",
    "        \n",
    "        # Save styled HTML\n",
    "        styled_df = df.style\\\n",
    "            .background_gradient(cmap='Blues', subset=['Test Accuracy', 'Test Macro F1'])\\\n",
    "            .format('{:.3f}', subset=['Train Accuracy', 'Test Accuracy', 'Test Macro F1', 'Test Weighted F1'])\\\n",
    "            .set_caption('Probe Performance Summary')\n",
    "        \n",
    "        with open(os.path.join(output_dir, 'metrics_summary.html'), 'w') as f:\n",
    "            f.write(styled_df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the GoEmotions dataset\n",
    "go_dataset = GoEmotionDataset(\n",
    "    train_path='Go_Emotion_Google/go_emotions_train.csv',\n",
    "    test_path='Go_Emotion_Google/go_emotions_test.csv',\n",
    "    val_path='Go_Emotion_Google/go_emotions_validation.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis limited to 1328 batches\n",
      "Identifying layer structure...\n",
      "Identified 29 layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting examples: 100%|██████████| 1328/1328 [06:22<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 21248\n",
      "Prepared metadata for 21248 valid examples\n",
      "Train set: 16998, Test set: 4250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches=1328\n",
    "# 2. Initialize the optimized probe analyzer with batch limit\n",
    "analyzer = OptimizedProbeAnalyzer(\n",
    "    hidden_states_dir='hidden_states',\n",
    "    go_dataset=go_dataset,\n",
    "    max_batches=max_batches,  # Limit to specified number of batches\n",
    "    chunk_size=100  # Process 50 files at a time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probes for layers: [0, 4, 10, 12, 14, 16, 18, 20, 24, 26, 28]\n",
      "Loading data with parallel processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 1328/1328 [06:49<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in 409.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load your analysis results (either from analyzer or saved file)\n",
    "results = analyzer.analyze_all_layers([0, 4,  10, 12, 14, 16, 18, 20, 24, 26, 28]) \n",
    "analyzer.save_results(\"full_results.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create visualizations\u001b[39;00m\n\u001b[32m      2\u001b[39m visualizer = ProbeVisualizer(results)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mvisualizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvisualize_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmy_report_figures\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Or make individual plots\u001b[39;00m\n\u001b[32m      5\u001b[39m visualizer.plot_confusion_matrices(\u001b[33m'\u001b[39m\u001b[33mlayer_10\u001b[39m\u001b[33m'\u001b[39m, output_dir=\u001b[33m'\u001b[39m\u001b[33mconfusion_mats\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mProbeVisualizer.visualize_all\u001b[39m\u001b[34m(self, output_dir, dpi)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate all visualizations with train/test separation\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplot_performance_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Renamed from plot_combined_metrics\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.plot_accuracy_comparison(output_dir, dpi)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mself\u001b[39m.plot_silhouette_scores(output_dir, dpi)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mProbeVisualizer.plot_performance_metrics\u001b[39m\u001b[34m(self, output_dir, dpi)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_performance_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_dir, dpi=\u001b[32m300\u001b[39m):\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Plot layer-wise performance metrics (originally called plot_combined_metrics)\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m     metrics = {\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28mself\u001b[39m.results[\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][layer][\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlayer_order\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m],\n\u001b[32m     49\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMacro F1\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28mself\u001b[39m.results[\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][layer][\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmacro_f1\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results[\u001b[33m'\u001b[39m\u001b[33mlayer_order\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m     50\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mWeighted F1\u001b[39m\u001b[33m'\u001b[39m: [\u001b[38;5;28mself\u001b[39m.results[\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][layer][\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mweighted_f1\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results[\u001b[33m'\u001b[39m\u001b[33mlayer_order\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     51\u001b[39m     }\n\u001b[32m     53\u001b[39m     layer_indices = [\u001b[38;5;28mint\u001b[39m(layer.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results[\u001b[33m'\u001b[39m\u001b[33mlayer_order\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m     55\u001b[39m     plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m8\u001b[39m), dpi=dpi)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create visualizations\n",
    "visualizer = ProbeVisualizer(results)\n",
    "visualizer.visualize_all(output_dir='my_report_figures', dpi=300)\n",
    "# Or make individual plots\n",
    "visualizer.plot_confusion_matrices('layer_10', output_dir='confusion_mats')\n",
    "visualizer.plot_tsne_projections('layer_20', output_dir='tsne_plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis phase (safe - no plotting)\n",
    "analyzer = OptimizedProbeAnalyzer(hidden_states_dir, go_dataset)\n",
    "results = analyzer.analyze_all_layers(layers_to_analyze)\n",
    "\n",
    "# Save results\n",
    "analyzer.save_results(\"probe_results.pt\")\n",
    "\n",
    "# Visualization phase (separate - can crash without losing data)\n",
    "try:\n",
    "    visualizer = ProbeVisualizer(results)\n",
    "    visualizer.visualize_all()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization failed but data is safe: {e}\")\n",
    "    # You can reload and retry:\n",
    "    results = OptimizedProbeAnalyzer.load_results(\"probe_results.pt\")\n",
    "    visualizer = ProbeVisualizer(results)\n",
    "    visualizer.visualize_all(\"alternative_output_dir\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts hidden states of QWEN model given different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Get_Go_Emo import get_go\n",
    "from Get_Isear import get_isr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>emotions</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>eebbqej</td>\n",
       "      <td>my favourite food is anything i didnt have to ...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>ambiguous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>ed00q6i</td>\n",
       "      <td>now if he does off himself, everyone will thin...</td>\n",
       "      <td>[neutral]</td>\n",
       "      <td>ambiguous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>eezlygj</td>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>[anger]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>ed7ypvh</td>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>[fear]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>ed0bdzj</td>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>[annoyance]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54258</th>\n",
       "      <td>It's pretty dangerous when the state decides w...</td>\n",
       "      <td>[14]</td>\n",
       "      <td>edyrazk</td>\n",
       "      <td>its pretty dangerous when the state decides wh...</td>\n",
       "      <td>[fear]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54259</th>\n",
       "      <td>I filed for divorce this morning. Hoping he mo...</td>\n",
       "      <td>[20]</td>\n",
       "      <td>edi2z3y</td>\n",
       "      <td>i filed for divorce this morning. hoping he mo...</td>\n",
       "      <td>[optimism]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54260</th>\n",
       "      <td>The last time it happened I just said, \"No\" an...</td>\n",
       "      <td>[10]</td>\n",
       "      <td>eewbqtx</td>\n",
       "      <td>the last time it happened i just said, no and ...</td>\n",
       "      <td>[disapproval]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54261</th>\n",
       "      <td>I can’t stand this arrogant prick he’s no bett...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>eefx57m</td>\n",
       "      <td>i cant stand this arrogant prick hes no better...</td>\n",
       "      <td>[annoyance]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54262</th>\n",
       "      <td>::but I like baby bangs:: /tiny voice</td>\n",
       "      <td>[18]</td>\n",
       "      <td>ed5h3jh</td>\n",
       "      <td>but i like baby bangs tiny voice</td>\n",
       "      <td>[love]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54263 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text labels       id  \\\n",
       "0      My favourite food is anything I didn't have to...   [27]  eebbqej   \n",
       "1      Now if he does off himself, everyone will thin...   [27]  ed00q6i   \n",
       "2                         WHY THE FUCK IS BAYLESS ISOING    [2]  eezlygj   \n",
       "3                            To make her feel threatened   [14]  ed7ypvh   \n",
       "4                                 Dirty Southern Wankers    [3]  ed0bdzj   \n",
       "...                                                  ...    ...      ...   \n",
       "54258  It's pretty dangerous when the state decides w...   [14]  edyrazk   \n",
       "54259  I filed for divorce this morning. Hoping he mo...   [20]  edi2z3y   \n",
       "54260  The last time it happened I just said, \"No\" an...   [10]  eewbqtx   \n",
       "54261  I can’t stand this arrogant prick he’s no bett...    [3]  eefx57m   \n",
       "54262              ::but I like baby bangs:: /tiny voice   [18]  ed5h3jh   \n",
       "\n",
       "                                              clean_text       emotions  \\\n",
       "0      my favourite food is anything i didnt have to ...      [neutral]   \n",
       "1      now if he does off himself, everyone will thin...      [neutral]   \n",
       "2                         why the fuck is bayless isoing        [anger]   \n",
       "3                            to make her feel threatened         [fear]   \n",
       "4                                 dirty southern wankers    [annoyance]   \n",
       "...                                                  ...            ...   \n",
       "54258  its pretty dangerous when the state decides wh...         [fear]   \n",
       "54259  i filed for divorce this morning. hoping he mo...     [optimism]   \n",
       "54260  the last time it happened i just said, no and ...  [disapproval]   \n",
       "54261  i cant stand this arrogant prick hes no better...    [annoyance]   \n",
       "54262                   but i like baby bangs tiny voice         [love]   \n",
       "\n",
       "       sentiment  \n",
       "0      ambiguous  \n",
       "1      ambiguous  \n",
       "2       negative  \n",
       "3       negative  \n",
       "4       negative  \n",
       "...          ...  \n",
       "54258   negative  \n",
       "54259   positive  \n",
       "54260   negative  \n",
       "54261   negative  \n",
       "54262   positive  \n",
       "\n",
       "[54263 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goEmo = get_go()\n",
    "goEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CITY</th>\n",
       "      <th>COUN</th>\n",
       "      <th>SUBJ</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>RELI</th>\n",
       "      <th>PRAC</th>\n",
       "      <th>FOCC</th>\n",
       "      <th>MOCC</th>\n",
       "      <th>...</th>\n",
       "      <th>RELA</th>\n",
       "      <th>VERBAL</th>\n",
       "      <th>NEUTRO</th>\n",
       "      <th>EMOT_T</th>\n",
       "      <th>Field3</th>\n",
       "      <th>Field2</th>\n",
       "      <th>MYKEY</th>\n",
       "      <th>SIT</th>\n",
       "      <th>STATE</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>joy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>110011</td>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>1</td>\n",
       "      <td>during the period of falling in love each time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fear</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>110012</td>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>1</td>\n",
       "      <td>when i was involved in a traffic accident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110013</td>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>1</td>\n",
       "      <td>when i was driving home after several days of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>110014</td>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>1</td>\n",
       "      <td>when i lost the person who meant the most to me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disgust</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>110015</td>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>the time i knocked a deer down the sight of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7661</th>\n",
       "      <td>331062</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3310623</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>1</td>\n",
       "      <td>two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7662</th>\n",
       "      <td>331062</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3310624</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>1</td>\n",
       "      <td>i had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7663</th>\n",
       "      <td>331062</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3310625</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>1</td>\n",
       "      <td>i was at home and i heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>331062</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>shame</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3310626</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "      <td>1</td>\n",
       "      <td>i did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7665</th>\n",
       "      <td>331062</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>guilt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3310627</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "      <td>1</td>\n",
       "      <td>i had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7666 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  CITY  COUN  SUBJ  SEX  AGE  RELI  PRAC  FOCC  MOCC  ...  RELA  \\\n",
       "0      11001     1     1     1    1   33     1     2     6     1  ...     3   \n",
       "1      11001     1     1     1    1   33     1     2     6     1  ...     2   \n",
       "2      11001     1     1     1    1   33     1     2     6     1  ...     1   \n",
       "3      11001     1     1     1    1   33     1     2     6     1  ...     1   \n",
       "4      11001     1     1     1    1   33     1     2     6     1  ...     2   \n",
       "...      ...   ...   ...   ...  ...  ...   ...   ...   ...   ...  ...   ...   \n",
       "7661  331062     1    33    62    2   21     2     1     7     7  ...     2   \n",
       "7662  331062     1    33    62    2   21     2     1     7     7  ...     0   \n",
       "7663  331062     1    33    62    2   21     2     1     7     7  ...     2   \n",
       "7664  331062     1    33    62    2   21     2     1     7     7  ...     0   \n",
       "7665  331062     1    33    62    2   21     2     1     7     7  ...     2   \n",
       "\n",
       "      VERBAL  NEUTRO   EMOT_T  Field3  Field2    MYKEY  \\\n",
       "0          2       0      joy       4       3   110011   \n",
       "1          0       0     fear       3       2   110012   \n",
       "2          0       0    anger       1       3   110013   \n",
       "3          0       2  sadness       4       4   110014   \n",
       "4          0       0  disgust       4       4   110015   \n",
       "...      ...     ...      ...     ...     ...      ...   \n",
       "7661       3       0    anger       1       2  3310623   \n",
       "7662       1       1  sadness       4       3  3310624   \n",
       "7663       0       0  disgust       1       2  3310625   \n",
       "7664       2       0    shame       1       3  3310626   \n",
       "7665       1       1    guilt       1       2  3310627   \n",
       "\n",
       "                                                    SIT  STATE  \\\n",
       "0     During the period of falling in love, each tim...      1   \n",
       "1            When I was involved in a traffic accident.      1   \n",
       "2     When I was driving home after  several days of...      1   \n",
       "3     When I lost the person who meant the most to me.       1   \n",
       "4     The time I knocked a deer down - the sight of ...      1   \n",
       "...                                                 ...    ...   \n",
       "7661  Two years back someone invited me to be the tu...      1   \n",
       "7662  I had taken the responsibility to do something...      1   \n",
       "7663  I was at home and I heard a loud sound of spit...      1   \n",
       "7664  I did not do the homework that the teacher had...      1   \n",
       "7665  I had shouted at my younger brother and he was...      1   \n",
       "\n",
       "                                             clean_text  \n",
       "0     during the period of falling in love each time...  \n",
       "1             when i was involved in a traffic accident  \n",
       "2     when i was driving home after several days of ...  \n",
       "3       when i lost the person who meant the most to me  \n",
       "4     the time i knocked a deer down the sight of th...  \n",
       "...                                                 ...  \n",
       "7661  two years back someone invited me to be the tu...  \n",
       "7662  i had taken the responsibility to do something...  \n",
       "7663  i was at home and i heard a loud sound of spit...  \n",
       "7664  i did not do the homework that the teacher had...  \n",
       "7665  i had shouted at my younger brother and he was...  \n",
       "\n",
       "[7666 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isear = get_isr()\n",
    "isear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "def extract_hidden_states(df, model_names, text_column='text', batch_size=8, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Extracts hidden states for each text in the DataFrame using specified models.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing the text data.\n",
    "        model_names (list): List of model names to extract hidden states from.\n",
    "        text_column (str): Name of the column containing text data.\n",
    "        batch_size (int): Batch size for processing.\n",
    "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added columns for each model's hidden states.\n",
    "    \"\"\"\n",
    "    for model_name in model_names:\n",
    "        print(f\"Processing model: {model_name}\")\n",
    "\n",
    "        # Load tokenizer and handle padding token\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token  # Use EOS token as PAD token for models like GPT-2\n",
    "\n",
    "        model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        texts = df[text_column].tolist()\n",
    "        tokenized = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Create DataLoader\n",
    "        input_ids = tokenized['input_ids']\n",
    "        attention_mask = tokenized['attention_mask']\n",
    "        dataset = TensorDataset(input_ids, attention_mask)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        \n",
    "        all_hidden_dicts = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                input_ids_batch, attention_mask_batch = [t.to(device) for t in batch]\n",
    "                \n",
    "                outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
    "                hidden_states = outputs.hidden_states  # Tuple of (layer 0, 1, ..., n)\n",
    "                \n",
    "                batch_size = input_ids_batch.size(0)\n",
    "                for i in range(batch_size):\n",
    "                    example_hidden = {}\n",
    "                    for layer_idx, layer in enumerate(hidden_states):\n",
    "                        # Extract [CLS] token embedding (first token) for BERT-style models\n",
    "                        # For GPT-2, use last token embedding (since there's no CLS token)\n",
    "                        if 'gpt' in model_name.lower():\n",
    "                            last_token_idx = attention_mask_batch[i].sum() - 1\n",
    "                            embedding = layer[i, last_token_idx, :].cpu().numpy().tolist()\n",
    "                        else:\n",
    "                            embedding = layer[i, 0, :].cpu().numpy().tolist()\n",
    "                        example_hidden[f'layer_{layer_idx}'] = embedding\n",
    "                    all_hidden_dicts.append(example_hidden)\n",
    "        \n",
    "        # Add hidden states as a new column\n",
    "        df[model_name] = all_hidden_dicts\n",
    "        \n",
    "        # Cleanup to free memory\n",
    "        del model, tokenizer\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model_names = ['bert-base-uncased', 'gpt2']  # Replace with your models\n",
    "\n",
    "# Process goEmo dataset\n",
    "goEmo_with_hidden = extract_hidden_states(goEmo, model_names)\n",
    "\n",
    "# Process isear dataset\n",
    "isear_with_hidden = extract_hidden_states(isear, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON files\n",
    "goEmo_with_hidden.to_json('goEmo_hidden_states.json', orient='records', lines=True)\n",
    "isear_with_hidden.to_json('isear_hidden_states.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add plots for each of the model names, a series of plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts hidden states of Any model given their names and different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Get_Go_Emo import get_go\n",
    "from Get_Isear import get_isr\n",
    "\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[27]</td>\n",
       "      <td>my favourite food is anything i didnt have to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[27]</td>\n",
       "      <td>now if he does off himself, everyone will thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2]</td>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14]</td>\n",
       "      <td>to make her feel threatened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3]</td>\n",
       "      <td>dirty southern wankers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[18]</td>\n",
       "      <td>i love name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[20]</td>\n",
       "      <td>woman here 50 per orgasm please! i could easil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[27]</td>\n",
       "      <td>a royal with creme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[ 4 15]</td>\n",
       "      <td>oh god yes. top quality cringe. thank you for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[27]</td>\n",
       "      <td>my name is name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                         clean_text\n",
       "0       [27]  my favourite food is anything i didnt have to ...\n",
       "1       [27]  now if he does off himself, everyone will thin...\n",
       "2        [2]                     why the fuck is bayless isoing\n",
       "3       [14]                        to make her feel threatened\n",
       "4        [3]                             dirty southern wankers\n",
       "..       ...                                                ...\n",
       "995     [18]                                        i love name\n",
       "996     [20]  woman here 50 per orgasm please! i could easil...\n",
       "997     [27]                                 a royal with creme\n",
       "998  [ 4 15]  oh god yes. top quality cringe. thank you for ...\n",
       "999     [27]                                    my name is name\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goEmo = get_go()\n",
    "goEmo = goEmo[:num_samples]\n",
    "goEmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>during the period of falling in love each time...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i was involved in a traffic accident</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when i was driving home after several days of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when i lost the person who meant the most to me</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the time i knocked a deer down the sight of th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>when i came to know that a girl i was fond of ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>a too eager approach by a dirty drunken person...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>i made a major mistake while learning how to u...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>i reproached my mothers cooking and criticised...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>i shot the decisive goal in an icehockey match</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text  labels\n",
       "0    during the period of falling in love each time...       1\n",
       "1            when i was involved in a traffic accident       2\n",
       "2    when i was driving home after several days of ...       3\n",
       "3      when i lost the person who meant the most to me       4\n",
       "4    the time i knocked a deer down the sight of th...       5\n",
       "..                                                 ...     ...\n",
       "995  when i came to know that a girl i was fond of ...       4\n",
       "996  a too eager approach by a dirty drunken person...       5\n",
       "997  i made a major mistake while learning how to u...       6\n",
       "998  i reproached my mothers cooking and criticised...       7\n",
       "999     i shot the decisive goal in an icehockey match       1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isear = get_isr()\n",
    "isear = isear[:num_samples]\n",
    "isear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os  # Import os module for directory operations\n",
    "\n",
    "def extract_hidden_states(df, model_names, text_column='clean_text', batch_size=16, dataset_name = \"no_dataset_selected\", device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"\n",
    "    Extracts hidden states for each text in the DataFrame using specified models.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing the text data.\n",
    "        model_names (list): List of model names to extract hidden states from.\n",
    "        text_column (str): Name of the column containing text data.\n",
    "        batch_size (int): Batch size for processing.\n",
    "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added columns for each model's hidden states.\n",
    "    \"\"\"\n",
    "    # Create hidden_states directory if it doesn't exist\n",
    "    os.makedirs('hidden_states', exist_ok=True)\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"\\nProcessing model: {model_name}\")\n",
    "        model_start_time = time.time()\n",
    "\n",
    "        # Load tokenizer and model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        \n",
    "        # Handle missing padding token\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        # Tokenize all texts\n",
    "        texts = df[text_column].tolist()\n",
    "        tokenized = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Create DataLoader\n",
    "        input_ids = tokenized['input_ids']\n",
    "        attention_mask = tokenized['attention_mask']\n",
    "        dataset = TensorDataset(input_ids, attention_mask)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "        \n",
    "        all_hidden_dicts = []\n",
    "        total_batches = len(dataloader)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(dataloader):\n",
    "                batch_start_time = time.time()\n",
    "                \n",
    "                input_ids_batch, attention_mask_batch = [t.to(device) for t in batch]\n",
    "                \n",
    "                # Get model outputs\n",
    "                outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n",
    "                hidden_states = outputs.hidden_states\n",
    "                \n",
    "                # Process each example in the batch\n",
    "                current_batch_size = input_ids_batch.size(0)\n",
    "                for i in range(current_batch_size):\n",
    "                    example_hidden = {}\n",
    "                    for layer_idx, layer in enumerate(hidden_states):\n",
    "                        cls_embedding = layer[i, 0, :].cpu().numpy().tolist()\n",
    "                        example_hidden[f'layer_{layer_idx}'] = cls_embedding\n",
    "                    all_hidden_dicts.append(example_hidden)\n",
    "                \n",
    "                # Calculate batch processing time\n",
    "                batch_time = time.time() - batch_start_time\n",
    "                \n",
    "                # Print progress with time information\n",
    "                print(\n",
    "                    f\"Batch {batch_idx + 1}/{total_batches} | \"\n",
    "                    f\"Time: {batch_time:.2f}s | \"\n",
    "                    f\"Avg: {(time.time() - model_start_time)/(batch_idx + 1):.2f}s/batch\", \n",
    "                    end='\\r'\n",
    "                )\n",
    "        \n",
    "        # Save individual model's hidden states to JSON file in hidden_states folder\n",
    "        output_filename = os.path.join('hidden_states', f\"{model_name}_{dataset_name}.json\")\n",
    "        with open(output_filename, 'w') as f:\n",
    "            json.dump(all_hidden_dicts, f, indent=2)  # indent for pretty-printing\n",
    "        \n",
    "        # Print final summary\n",
    "        total_time = time.time() - model_start_time\n",
    "        print(f\"\\nCompleted {model_name} in {total_time:.2f}s ({total_time/len(df):.4f}s/sample)\")\n",
    "        print(f\"Saved hidden states to {output_filename}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del model, tokenizer\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save complete DataFrame with all hidden states to a single JSON file\n",
    "    final_output_path = os.path.join('hidden_states', 'all_hidden_states.json')\n",
    "    df.to_json(final_output_path, orient='records', indent=2)\n",
    "    print(f\"\\nSaved complete DataFrame with all hidden states to {final_output_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing model: bert-base-uncased\n",
      "Batch 63/63 | Time: 0.32s | Avg: 0.74s/batch\n",
      "Completed bert-base-uncased in 62.90s (0.0629s/sample)\n",
      "Saved hidden states to hidden_states/bert-base-uncased_goEmo.json\n",
      "\n",
      "Processing model: gpt2\n",
      "Batch 63/63 | Time: 0.35s | Avg: 0.72s/batch\n",
      "Completed gpt2 in 58.46s (0.0585s/sample)\n",
      "Saved hidden states to hidden_states/gpt2_goEmo.json\n",
      "\n",
      "Saved complete DataFrame with all hidden states to hidden_states/all_hidden_states.json\n",
      "\n",
      "Processing model: bert-base-uncased\n",
      "Batch 63/63 | Time: 0.56s | Avg: 1.08s/batch\n",
      "Completed bert-base-uncased in 81.43s (0.0814s/sample)\n",
      "Saved hidden states to hidden_states/bert-base-uncased_isear.json\n",
      "\n",
      "Processing model: gpt2\n",
      "Batch 63/63 | Time: 0.62s | Avg: 1.43s/batch\n",
      "Completed gpt2 in 104.75s (0.1048s/sample)\n",
      "Saved hidden states to hidden_states/gpt2_isear.json\n",
      "\n",
      "Saved complete DataFrame with all hidden states to hidden_states/all_hidden_states.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "model_names = ['bert-base-uncased', 'gpt2']  # Replace with your models\n",
    "\n",
    "# Process goEmo dataset\n",
    "goEmo_with_hidden = extract_hidden_states(goEmo, model_names, dataset_name=\"goEmo\")\n",
    "\n",
    "# Process isear dataset\n",
    "isear_with_hidden = extract_hidden_states(isear, model_names, dataset_name=\"isear\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add plots for each of the model names, a series of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import describe_hidden_states, analyze_hidden_states, describe_all_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing gpt2_goEmo.json...\n",
      "Model: gpt2\n",
      "Dataset: \n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "Consistent layers across samples: True\n",
      "Consistent dimensions: True\n",
      "\n",
      "Analyzing bert-base-uncased_isear.json...\n",
      "Model: bert-base-uncased\n",
      "Dataset: \n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "Consistent layers across samples: True\n",
      "Consistent dimensions: True\n",
      "\n",
      "Analyzing gpt2_isear.json...\n",
      "Model: gpt2\n",
      "Dataset: \n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "Consistent layers across samples: True\n",
      "Consistent dimensions: True\n",
      "\n",
      "Analyzing bert-base-uncased_goEmo.json...\n",
      "Model: bert-base-uncased\n",
      "Dataset: \n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "Consistent layers across samples: True\n",
      "Consistent dimensions: True\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "analysis = analyze_hidden_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 5 hidden state files to analyze:\n",
      "\n",
      "==================================================\n",
      "File 1/5: gpt2_goEmo.json\n",
      "==================================================\n",
      "\n",
      "=== Hidden States Data Structure ===\n",
      "File: gpt2_goEmo.json\n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "\n",
      "=== Structure Details ===\n",
      "1. Top level: List of samples (order matches input DataFrame)\n",
      "2. Each sample: Dictionary with layer-wise CLS token embeddings\n",
      "3. Layer keys: 'layer_0' to 'layer_N' where N = num_layers-1\n",
      "4. Each layer: List of floats (length = hidden_dimension)\n",
      "\n",
      "=== Example Samples ===\n",
      "\n",
      "Sample 1:\n",
      "  layer_0: [0.10145839303731918, -0.17585629224777222, 0.11894845217466354, 0.10073922574520111, -0.03555705398321152, ...] (total 768 values)\n",
      "  layer_1: [-0.12574833631515503, -0.9124440550804138, -0.830676794052124, -0.00699269026517868, -0.7556575536727905, ...] (total 768 values)\n",
      "  layer_10: [-0.32650119066238403, -1.6769062280654907, -0.5606088638305664, -0.1685718595981598, 1.2347315549850464, ...] (total 768 values)\n",
      "  layer_11: [-0.4182337522506714, -1.421185851097107, -0.8745468854904175, -0.18449610471725464, 1.2268154621124268, ...] (total 768 values)\n",
      "  layer_12: [-0.09733543545007706, -0.045332178473472595, -0.39655423164367676, 0.03356175497174263, -0.00915573164820671, ...] (total 768 values)\n",
      "  layer_2: [-0.1876540184020996, -1.5682299137115479, -0.3692511320114136, 0.15338927507400513, 0.26241034269332886, ...] (total 768 values)\n",
      "  layer_3: [0.037581413984298706, -1.79460608959198, -0.29985910654067993, 0.2668178677558899, 0.48550018668174744, ...] (total 768 values)\n",
      "  layer_4: [0.06319747120141983, -1.7886672019958496, -0.21029403805732727, 0.2516323924064636, 0.6565145254135132, ...] (total 768 values)\n",
      "  layer_5: [-0.1172194704413414, -1.888351559638977, -0.2670380473136902, 0.2079249620437622, 0.6740637421607971, ...] (total 768 values)\n",
      "  layer_6: [-0.12318834662437439, -1.9818657636642456, -0.17529095709323883, 0.1432759016752243, 0.8975815176963806, ...] (total 768 values)\n",
      "  layer_7: [-0.19786258041858673, -1.981252670288086, -0.1268434226512909, 0.06302151829004288, 1.0681356191635132, ...] (total 768 values)\n",
      "  layer_8: [-0.272768497467041, -1.851593017578125, -0.28726089000701904, -0.09145525842905045, 1.196213960647583, ...] (total 768 values)\n",
      "  layer_9: [-0.24898211658000946, -1.7767221927642822, -0.303594172000885, -0.12611407041549683, 1.1874295473098755, ...] (total 768 values)\n",
      "\n",
      "Sample 2:\n",
      "  layer_0: [-0.06327484548091888, -0.30215054750442505, 0.02997773140668869, -0.0005503175780177116, 0.3052350878715515, ...] (total 768 values)\n",
      "  layer_1: [-1.2447245121002197, 0.00992700457572937, -0.5430357456207275, -0.27994686365127563, -0.10614669322967529, ...] (total 768 values)\n",
      "  layer_10: [-1.0845500230789185, -0.31305602192878723, -0.3287430703639984, -0.32226869463920593, 1.1730979681015015, ...] (total 768 values)\n",
      "  layer_11: [-1.248541235923767, -0.116449736058712, -0.6725118160247803, -0.3207906484603882, 1.0257971286773682, ...] (total 768 values)\n",
      "  layer_12: [-0.1895839422941208, 0.04109602048993111, -0.35846877098083496, -0.03197738900780678, -0.07300437241792679, ...] (total 768 values)\n",
      "  layer_2: [-1.032999038696289, -0.29811784625053406, -0.04633095860481262, 0.00922420620918274, 0.6151688694953918, ...] (total 768 values)\n",
      "  layer_3: [-0.7114225625991821, -0.4781632423400879, -0.005949065089225769, 0.15114882588386536, 0.6734657287597656, ...] (total 768 values)\n",
      "  layer_4: [-0.6561185717582703, -0.47223401069641113, 0.06650406867265701, 0.13215665519237518, 0.841669499874115, ...] (total 768 values)\n",
      "  layer_5: [-0.8295726776123047, -0.5506699085235596, -0.0024507641792297363, 0.08149414509534836, 0.819480836391449, ...] (total 768 values)\n",
      "  layer_6: [-0.8469754457473755, -0.6263871192932129, 0.061930157244205475, 0.01058661937713623, 1.0176525115966797, ...] (total 768 values)\n",
      "  layer_7: [-0.9536353349685669, -0.616728663444519, 0.10808505117893219, -0.044572196900844574, 1.1245996952056885, ...] (total 768 values)\n",
      "  layer_8: [-0.9873324036598206, -0.49224355816841125, -0.0354500412940979, -0.19762086868286133, 1.2029660940170288, ...] (total 768 values)\n",
      "  layer_9: [-0.9798339605331421, -0.4462290406227112, -0.05513733625411987, -0.3039930462837219, 1.1786978244781494, ...] (total 768 values)\n",
      "\n",
      "=== Value Statistics ===\n",
      "Global mean: 3.2778\n",
      "Global std: 89.9293\n",
      "Min value: -81.2363\n",
      "Max value: 3098.1638\n",
      "\n",
      "==================================================\n",
      "File 2/5: all_hidden_states.json\n",
      "==================================================\n",
      "\n",
      "=== Hidden States Data Structure ===\n",
      "File: all_hidden_states.json\n",
      "Total samples: 1000\n",
      "Number of layers: 2\n",
      "Error analyzing all_hidden_states.json: 'layer_0'\n",
      "\n",
      "==================================================\n",
      "File 3/5: bert-base-uncased_isear.json\n",
      "==================================================\n",
      "\n",
      "=== Hidden States Data Structure ===\n",
      "File: bert-base-uncased_isear.json\n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "\n",
      "=== Structure Details ===\n",
      "1. Top level: List of samples (order matches input DataFrame)\n",
      "2. Each sample: Dictionary with layer-wise CLS token embeddings\n",
      "3. Layer keys: 'layer_0' to 'layer_N' where N = num_layers-1\n",
      "4. Each layer: List of floats (length = hidden_dimension)\n",
      "\n",
      "=== Example Samples ===\n",
      "\n",
      "Sample 1:\n",
      "  layer_0: [0.16855061054229736, -0.2857673764228821, -0.3261256515979767, -0.11222130060195923, 0.034265510737895966, ...] (total 768 values)\n",
      "  layer_1: [0.07818152010440826, 0.1203693300485611, -0.09967078268527985, -0.18330858647823334, 0.2009025663137436, ...] (total 768 values)\n",
      "  layer_10: [-0.3607119023799896, -1.097942590713501, -0.6669844388961792, -0.4707266092300415, -0.4027642607688904, ...] (total 768 values)\n",
      "  layer_11: [-0.17007166147232056, -0.8802974820137024, -0.5655235648155212, -0.5900537967681885, -0.7847605347633362, ...] (total 768 values)\n",
      "  layer_12: [-0.17852964997291565, -0.2835945785045624, -0.5426044464111328, -0.006640879437327385, -0.3098653256893158, ...] (total 768 values)\n",
      "  layer_2: [-0.06798712909221649, -0.13058137893676758, -0.1859755963087082, -0.09387675672769547, 0.17389431595802307, ...] (total 768 values)\n",
      "  layer_3: [0.03126085549592972, -0.24951016902923584, -0.12100515514612198, -0.019992634654045105, 0.23069174587726593, ...] (total 768 values)\n",
      "  layer_4: [0.2667112946510315, -0.6816464066505432, -0.7325009703636169, -0.30573952198028564, -0.04236563667654991, ...] (total 768 values)\n",
      "  layer_5: [0.07966883480548859, -0.7470031976699829, -0.5054234862327576, -0.40824443101882935, -0.4332488477230072, ...] (total 768 values)\n",
      "  layer_6: [0.22352777421474457, -1.152409315109253, -0.3519902229309082, -0.8121660947799683, -0.386301189661026, ...] (total 768 values)\n",
      "  layer_7: [-0.05539736524224281, -1.0197564363479614, -0.45916005969047546, -0.3349216878414154, -0.18140196800231934, ...] (total 768 values)\n",
      "  layer_8: [-0.006348516792058945, -0.8146196007728577, -0.7693778872489929, -0.2074158936738968, -0.32677534222602844, ...] (total 768 values)\n",
      "  layer_9: [-0.21680092811584473, -0.6603012084960938, -0.8273433446884155, -0.2775801718235016, -0.27453604340553284, ...] (total 768 values)\n",
      "\n",
      "Sample 2:\n",
      "  layer_0: [0.16855061054229736, -0.2857673764228821, -0.3261256515979767, -0.11222130060195923, 0.034265510737895966, ...] (total 768 values)\n",
      "  layer_1: [0.12120518088340759, 0.07476001232862473, -0.08371710777282715, -0.18885241448879242, 0.11465440690517426, ...] (total 768 values)\n",
      "  layer_10: [-0.29031652212142944, -0.650696873664856, -0.8045386672019958, -0.19014939665794373, -0.17440924048423767, ...] (total 768 values)\n",
      "  layer_11: [0.08270931988954544, -0.2443961203098297, -0.46699410676956177, -0.38023778796195984, -0.3778880834579468, ...] (total 768 values)\n",
      "  layer_12: [-0.034215331077575684, -0.053637705743312836, -0.36707988381385803, -0.0881815105676651, -0.12100041657686234, ...] (total 768 values)\n",
      "  layer_2: [-0.043657854199409485, -0.2024230659008026, -0.18111062049865723, -0.06121835857629776, 0.1692989468574524, ...] (total 768 values)\n",
      "  layer_3: [-0.0526958666741848, -0.2718624770641327, -0.05859679728746414, 0.04383017495274544, 0.2417048066854477, ...] (total 768 values)\n",
      "  layer_4: [0.033516451716423035, -0.43790385127067566, -0.46759864687919617, 0.030106639489531517, 0.05644376575946808, ...] (total 768 values)\n",
      "  layer_5: [-0.28972524404525757, -0.5118478536605835, -0.3382924795150757, -0.07489816844463348, -0.18265840411186218, ...] (total 768 values)\n",
      "  layer_6: [-0.02121680974960327, -0.7088289260864258, -0.35722339153289795, -0.8436592817306519, -0.16422143578529358, ...] (total 768 values)\n",
      "  layer_7: [-0.18693478405475616, -0.6474778056144714, -0.5037103891372681, -0.361613392829895, 0.18281078338623047, ...] (total 768 values)\n",
      "  layer_8: [-0.33275309205055237, -0.7099671363830566, -0.901960015296936, -0.3403124213218689, -0.3006436824798584, ...] (total 768 values)\n",
      "  layer_9: [-0.19572558999061584, -0.3948715329170227, -1.1467119455337524, -0.005967635661363602, -0.20209042727947235, ...] (total 768 values)\n",
      "\n",
      "=== Value Statistics ===\n",
      "Global mean: -0.0223\n",
      "Global std: 0.5997\n",
      "Min value: -14.0985\n",
      "Max value: 4.4444\n",
      "\n",
      "==================================================\n",
      "File 4/5: gpt2_isear.json\n",
      "==================================================\n",
      "\n",
      "=== Hidden States Data Structure ===\n",
      "File: gpt2_isear.json\n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "\n",
      "=== Structure Details ===\n",
      "1. Top level: List of samples (order matches input DataFrame)\n",
      "2. Each sample: Dictionary with layer-wise CLS token embeddings\n",
      "3. Layer keys: 'layer_0' to 'layer_N' where N = num_layers-1\n",
      "4. Each layer: List of floats (length = hidden_dimension)\n",
      "\n",
      "=== Example Samples ===\n",
      "\n",
      "Sample 1:\n",
      "  layer_0: [-0.12306562811136246, -0.3259602189064026, 0.2326592206954956, 0.1933799386024475, 0.15132078528404236, ...] (total 768 values)\n",
      "  layer_1: [0.27424174547195435, -0.3367936611175537, -0.8121678829193115, 1.2969383001327515, -1.0123419761657715, ...] (total 768 values)\n",
      "  layer_10: [0.5693485736846924, -0.17577871680259705, -0.9180302023887634, 0.9304264783859253, -0.13395342230796814, ...] (total 768 values)\n",
      "  layer_11: [0.38375818729400635, -1.5176832675933838e-05, -1.2416362762451172, 0.9896742105484009, -0.24451863765716553, ...] (total 768 values)\n",
      "  layer_12: [-0.046381548047065735, 0.0008245334029197693, -0.4836856722831726, 0.10342144221067429, -0.1865054965019226, ...] (total 768 values)\n",
      "  layer_2: [0.6849415302276611, -0.21129673719406128, -0.4898482859134674, 1.3904083967208862, -0.8530184030532837, ...] (total 768 values)\n",
      "  layer_3: [0.8959903717041016, -0.34701550006866455, -0.6563684940338135, 1.2536077499389648, -0.5873984098434448, ...] (total 768 values)\n",
      "  layer_4: [0.9296973347663879, -0.33227938413619995, -0.5667762160301208, 1.2281103134155273, -0.3985744118690491, ...] (total 768 values)\n",
      "  layer_5: [0.7335023880004883, -0.3676457405090332, -0.6424525380134583, 1.1459447145462036, -0.383395791053772, ...] (total 768 values)\n",
      "  layer_6: [0.735917866230011, -0.45938917994499207, -0.5889904499053955, 1.1203432083129883, -0.19800114631652832, ...] (total 768 values)\n",
      "  layer_7: [0.6682825684547424, -0.4430654048919678, -0.5652779340744019, 1.0588722229003906, -0.08247343450784683, ...] (total 768 values)\n",
      "  layer_8: [0.6222254037857056, -0.30169394612312317, -0.6696698665618896, 0.9724399447441101, -0.03876950219273567, ...] (total 768 values)\n",
      "  layer_9: [0.6597424745559692, -0.2805628776550293, -0.6781833171844482, 0.9258005619049072, -0.11368221789598465, ...] (total 768 values)\n",
      "\n",
      "Sample 2:\n",
      "  layer_0: [-0.09615054726600647, -0.23981714248657227, 0.12837594747543335, 0.061031244695186615, 0.08881039917469025, ...] (total 768 values)\n",
      "  layer_1: [-0.6137608289718628, 0.14881813526153564, 0.383500874042511, 0.7700175046920776, -1.1664398908615112, ...] (total 768 values)\n",
      "  layer_10: [-0.44628721475601196, -0.24568966031074524, -0.05028173327445984, 0.31625449657440186, -0.07153429090976715, ...] (total 768 values)\n",
      "  layer_11: [-0.6241341233253479, -0.10710039734840393, -0.3752368092536926, 0.30612242221832275, -0.183580219745636, ...] (total 768 values)\n",
      "  layer_12: [-0.14047086238861084, 0.007316308096051216, -0.33056801557540894, 0.0783715695142746, -0.21262575685977936, ...] (total 768 values)\n",
      "  layer_2: [-0.15136456489562988, -0.11869107186794281, 0.27392807602882385, 0.8067513704299927, -0.9279037117958069, ...] (total 768 values)\n",
      "  layer_3: [-0.06729444116353989, -0.3549940586090088, 0.27367061376571655, 0.7611008286476135, -0.6283906102180481, ...] (total 768 values)\n",
      "  layer_4: [-0.04181777685880661, -0.3527728021144867, 0.3431195914745331, 0.73304283618927, -0.4559585452079773, ...] (total 768 values)\n",
      "  layer_5: [-0.20894594490528107, -0.42866143584251404, 0.27268433570861816, 0.6788877248764038, -0.4552643299102783, ...] (total 768 values)\n",
      "  layer_6: [-0.2145569771528244, -0.515887975692749, 0.3101029396057129, 0.6306186318397522, -0.26341843605041504, ...] (total 768 values)\n",
      "  layer_7: [-0.2829905152320862, -0.5035116076469421, 0.32203972339630127, 0.5542623996734619, -0.11817042529582977, ...] (total 768 values)\n",
      "  layer_8: [-0.33638104796409607, -0.4008110463619232, 0.2087181806564331, 0.4235926568508148, -0.020137935876846313, ...] (total 768 values)\n",
      "  layer_9: [-0.3074658215045929, -0.3495330214500427, 0.20323681831359863, 0.34878799319267273, -0.06664346903562546, ...] (total 768 values)\n",
      "\n",
      "=== Value Statistics ===\n",
      "Global mean: 3.2838\n",
      "Global std: 89.9896\n",
      "Min value: -82.5294\n",
      "Max value: 3111.3281\n",
      "\n",
      "==================================================\n",
      "File 5/5: bert-base-uncased_goEmo.json\n",
      "==================================================\n",
      "\n",
      "=== Hidden States Data Structure ===\n",
      "File: bert-base-uncased_goEmo.json\n",
      "Total samples: 1000\n",
      "Number of layers: 13\n",
      "Hidden dimension size: 768\n",
      "\n",
      "=== Structure Details ===\n",
      "1. Top level: List of samples (order matches input DataFrame)\n",
      "2. Each sample: Dictionary with layer-wise CLS token embeddings\n",
      "3. Layer keys: 'layer_0' to 'layer_N' where N = num_layers-1\n",
      "4. Each layer: List of floats (length = hidden_dimension)\n",
      "\n",
      "=== Example Samples ===\n",
      "\n",
      "Sample 1:\n",
      "  layer_0: [0.16855061054229736, -0.2857673764228821, -0.3261256515979767, -0.11222130060195923, 0.034265510737895966, ...] (total 768 values)\n",
      "  layer_1: [0.009634755551815033, 0.12585924565792084, -0.2121667116880417, -0.3707119822502136, 0.25970780849456787, ...] (total 768 values)\n",
      "  layer_10: [0.4301041066646576, -0.1420818418264389, -0.4845257103443146, -0.4250118136405945, -0.677425742149353, ...] (total 768 values)\n",
      "  layer_11: [0.4321022033691406, -0.0798761174082756, -0.06749485433101654, -0.8322005271911621, -0.41001081466674805, ...] (total 768 values)\n",
      "  layer_12: [-0.29424819350242615, 0.4935801923274994, -0.18679241836071014, -0.5099745988845825, -0.19286209344863892, ...] (total 768 values)\n",
      "  layer_2: [-0.03599797934293747, -0.14989805221557617, -0.49372681975364685, -0.22598183155059814, 0.26081347465515137, ...] (total 768 values)\n",
      "  layer_3: [-0.01920533925294876, -0.3414633572101593, -0.28124088048934937, -0.07460866123437881, 0.3883967399597168, ...] (total 768 values)\n",
      "  layer_4: [0.17490020394325256, -0.6138384938240051, -0.7254369854927063, -0.40643221139907837, -0.10364237427711487, ...] (total 768 values)\n",
      "  layer_5: [0.09333203732967377, -0.583931565284729, -0.4495832324028015, -0.334669291973114, -0.2901483178138733, ...] (total 768 values)\n",
      "  layer_6: [0.15789180994033813, -0.8390677571296692, -0.3444121479988098, -0.8189709782600403, -0.15613171458244324, ...] (total 768 values)\n",
      "  layer_7: [0.5003141760826111, -0.436442494392395, -0.5087525248527527, -0.7088134288787842, -0.11867056787014008, ...] (total 768 values)\n",
      "  layer_8: [0.41800278425216675, -0.26366502046585083, -0.6340272426605225, -0.33275994658470154, -0.31466877460479736, ...] (total 768 values)\n",
      "  layer_9: [0.3009937107563019, -0.08319775015115738, -0.5860978364944458, -0.18439151346683502, -0.6578170657157898, ...] (total 768 values)\n",
      "\n",
      "Sample 2:\n",
      "  layer_0: [0.16855061054229736, -0.2857673764228821, -0.3261256515979767, -0.11222130060195923, 0.034265510737895966, ...] (total 768 values)\n",
      "  layer_1: [0.0575006902217865, 0.04165010154247284, -0.16110050678253174, -0.19567297399044037, 0.1825428456068039, ...] (total 768 values)\n",
      "  layer_10: [0.5153101682662964, -0.1001477763056755, 0.20715826749801636, 0.17080308496952057, -0.9460656642913818, ...] (total 768 values)\n",
      "  layer_11: [0.5222355127334595, 0.04834165424108505, 0.28382790088653564, 0.24268727004528046, -0.5757140517234802, ...] (total 768 values)\n",
      "  layer_12: [0.35660886764526367, 0.118930883705616, 0.5933176875114441, 0.27288052439689636, -0.3262355923652649, ...] (total 768 values)\n",
      "  layer_2: [-0.03304566442966461, -0.15940341353416443, -0.395071417093277, -0.06258483976125717, 0.07408269494771957, ...] (total 768 values)\n",
      "  layer_3: [0.03449993580579758, -0.33763420581817627, -0.19183525443077087, 0.06439502537250519, 0.22010599076747894, ...] (total 768 values)\n",
      "  layer_4: [0.2677012085914612, -0.5022275447845459, -0.5820803642272949, -0.21775339543819427, -0.03665098547935486, ...] (total 768 values)\n",
      "  layer_5: [0.18464791774749756, -0.45147809386253357, -0.36866962909698486, -0.15703704953193665, 0.013428635895252228, ...] (total 768 values)\n",
      "  layer_6: [0.3802955746650696, -0.667512834072113, -0.2534245252609253, -0.7153435945510864, -0.08543926477432251, ...] (total 768 values)\n",
      "  layer_7: [0.590516984462738, -0.3996807038784027, 0.10438369959592819, -0.15531642735004425, -0.2587353587150574, ...] (total 768 values)\n",
      "  layer_8: [0.7117567658424377, -0.4167126417160034, -0.22799785435199738, 0.060147788375616074, -0.3070001006126404, ...] (total 768 values)\n",
      "  layer_9: [0.541312038898468, -0.2663569450378418, -0.18875233829021454, 0.021380463615059853, -0.5668383836746216, ...] (total 768 values)\n",
      "\n",
      "=== Value Statistics ===\n",
      "Global mean: -0.0221\n",
      "Global std: 0.6010\n",
      "Min value: -14.0200\n",
      "Max value: 4.5756\n",
      "\n",
      "Analysis complete for all files!\n"
     ]
    }
   ],
   "source": [
    "# Describe all files in the default hidden_states directory\n",
    "describe_all_hidden_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
